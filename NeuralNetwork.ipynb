{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Martin Chibwe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy  \n",
    "import scipy.special #for sigmoid\n",
    "import matplotlib.pyplot\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "    \n",
    "    \n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # set number of nodes in each input, hidden, output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # link weight matrices, wih and who\n",
    "        # weights inside the arrays are w_i_j, where link is from node i to node j in the next layer\n",
    "        # w11 w21\n",
    "        # w12 w22 etc \n",
    "        self.wih = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        self.inverse_activation_function = lambda x: scipy.special.logit(x)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors) \n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        \n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "    \n",
    "    \n",
    "    # backquery the neural network\n",
    "    # we'll use the same termnimology to each item, \n",
    "    # eg target are the values at the right of the network, albeit used as input\n",
    "    # eg hidden_output is the signal to the right of the middle nodes\n",
    "    def backquery(self, targets_list):\n",
    "        # transpose the targets list to a vertical array\n",
    "        final_outputs = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate the signal into the final output layer\n",
    "        final_inputs = self.inverse_activation_function(final_outputs)\n",
    "\n",
    "        # calculate the signal out of the hidden layer\n",
    "        hidden_outputs = numpy.dot(self.who.T, final_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        hidden_outputs -= numpy.min(hidden_outputs)\n",
    "        hidden_outputs /= numpy.max(hidden_outputs)\n",
    "        hidden_outputs *= 0.98\n",
    "        hidden_outputs += 0.01\n",
    "        \n",
    "        # calculate the signal into the hideen layer\n",
    "        hidden_inputs = self.inverse_activation_function(hidden_outputs)\n",
    "        \n",
    "        # calculate the signal out of the input layer\n",
    "        inputs = numpy.dot(self.wih.T, hidden_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        inputs -= numpy.min(inputs)\n",
    "        inputs /= numpy.max(inputs)\n",
    "        inputs *= 0.98\n",
    "        inputs += 0.01\n",
    "        \n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#n.query([1.0,0.5,-1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function print>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data_file = open(\"/Users/martinchibwe/Dropbox/Neural Network/mnist_dataset/mnist_train_100.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #Train the neural network\n",
    "# #Go through all records  in the training data set\n",
    "\n",
    "# for record in training_data_list:\n",
    "    \n",
    "    \n",
    "#     #split the record by the ',' com\n",
    "\n",
    "#     all_values = data_list[1].split(',')\n",
    "#     #scale and shift the inputs \n",
    "#     inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01 \n",
    "#     #create the target values (all 0.01, except the desired label which is 0.99)\n",
    "#     targets = np.zeros(output_nodes) + 0.01\n",
    "    \n",
    "#     # all_values[0] is the target label for this record \n",
    "#     targets[(all_values[0])] = 0.99\n",
    "#     n.train(inputs, targets)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# train the neural network\n",
    "\n",
    "# epochs is the number of times the training data set is used for training\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    # go through all records in the training data set\n",
    "    for record in training_data_list:\n",
    "        # split the record by the ',' commas\n",
    "        all_values = record.split(',')\n",
    "        # scale and shift the inputs\n",
    "        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x110062908>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADxZJREFUeJzt3X+MVfWZx/HPg4pKiT8gyxCBAtXYNZsY0rUmG1e9xN2C\npgnSKMtq/MESUpKiuE0UITEMsn+0xBAhBiOWGqjVtlvDYv9xbTXXH5GuZIVdEJQaMzBOZcANKGg0\nsDz7x1zYO+Pc77nMuT/O8LxfycQ75zlnzjMHP3POvd9z79fcXQBiGdHuBgC0HsEHAiL4QEAEHwiI\n4AMBEXwgoFzBN7OZZvaeme01syWNagpAc9lQx/HNbISkvZJukvRnSdskzXX39wasx40CQJu4uw22\nPM8Z/1pJf3L3fe5+XNKvJM2qsfPTX8uXL+/3fdG+6O/s7a/IvTWjv5Q8wZ8gqbvq+48qywAUHC/u\nAQGdm2PbHknfrPp+YmXZ13R2dp5+fMkll+TYZfOVSqV2t5BEf0NX5N6k/P2Vy2WVy+W61s3z4t45\nkt5X34t7H0t6W9I/uvueAev5UPcBYOjMTF7jxb0hn/Hd/X/NbJGkl9X3lGHDwNADKKYhn/Hr3gFn\nfKAtUmd8XtwDAiL4QEAEHwiI4AMBEXwgIIIPBETwgYAIPhAQwQcCIvhAQAQfCIjgAwERfCAggg8E\nRPCBgAg+EBDBBwIi+EBABB8IiOADARF8ICCCDwRE8IGA8kyhhQCy5kTo7u6uWVu7dm1y28cffzxZ\nf+CBB5L1xYsXJ+uTJk1K1iPjjA8ERPCBgAg+EBDBBwIi+EBABB8IiOADAVmeuevNrEvSp5JOSjru\n7tcOso7n2QeaK+vfpqenJ1mfNm1azdqRI0dy7dts0KndTxszZkyyfvDgwWT9bGdmcvdBD2LeG3hO\nSiq5++GcPwdAC+W91LcG/AwALZY3tC7p92a2zcwWNKIhAM2X91L/Onf/2Mz+Qn1/APa4+5sDV+rs\n7Dz9uFQqqVQq5dwtgIHK5bLK5XJd6+Z6ca/fDzJbLumou68esJwX9wqMF/fOXqkX94Z8qW9mo8xs\ndOXxNyR9T9Kuof48AK2T51K/Q9JmM/PKz/mlu7/cmLYANFPDLvVr7oBL/bbKOvb79u1L1qdPn56s\n79+/v2Yt61L9oosuStbPP//8ZP3QoUPJ+t69e5P1yZMnJ+vnnHNOsl50TbnUBzB8EXwgIIIPBETw\ngYAIPhAQwQcCIvhAQIzjF1zWsTt+/HiynjVOf/PNNyfrXV1dyXqqv6xx/BtvvDFZX7lyZbJ+/fXX\nJ+tZ+3/qqaeS9fnz5yfrRcc4PoB+CD4QEMEHAiL4QEAEHwiI4AMBEXwgoLyfuYc2e+ihh5L1J554\nItfPb+Y9GK+99lqy/sUXXyTrs2fPTtY3b96crG/fvj1ZP5txxgcCIvhAQAQfCIjgAwERfCAggg8E\nRPCBgBjHb7OscfLu7u5k/dlnn83187NkjZWn6nfffXdy20mTJiXrV111VbKedQ/DCy+8kKxH/pwI\nzvhAQAQfCIjgAwERfCAggg8ERPCBgAg+EFDm5+qb2QZJ35fU6+5XV5ZdKunXkiZL6pI0x90/rbF9\n6M/Vz/rde3p6kvVp06Yl60eOHDnjnqrdeeedyfr69euT9d27d9esvfPOO8lt586dm6yPGjUqWc86\ntuedd16yPnr06GR9165dyXrWfQjtlvdz9Z+RNGPAsocl/cHdvy3pVUlL87UIoJUyg+/ub0o6PGDx\nLEkbK483Srq1wX0BaKKhPscf5+69kuTuBySNa1xLAJqtUffqJ59sdXZ2nn5cKpVUKpUatFsAp5TL\nZZXL5brWHWrwe82sw917zWy8pIOplauDD6A5Bp5UV6xYUXPdei/1rfJ1youS7q08vkfSljNpEEB7\nZQbfzJ6T9JakK81sv5nNk/QTSX9vZu9LuqnyPYBhIvNS393vqFH6uwb3MixljSV/8sknyfqqVauS\n9cOHBw6o9NfR0ZGsT506NVlfuHBhsj5y5MhkPXWfQdY9CFmy5rfP6/PPP0/WH3vssWR9zZo1jWyn\npbhzDwiI4AMBEXwgIIIPBETwgYAIPhAQwQcC4nP1M2SN0584cSJZf/DBB5P1rM/Fv/jii5P1l156\nKVm/4oorkvXjx48n680eSy+yDz/8sN0tNA1nfCAggg8ERPCBgAg+EBDBBwIi+EBABB8IiHH8nPbv\n35+sZ43TZ9m6dWuyfuWVV+b6+RdeeGGu7TE8ccYHAiL4QEAEHwiI4AMBEXwgIIIPBETwgYAYx89p\n0aJFyXrW+/lnz56drGeN00d+v3yWkydPJusjRqTPe1n/dsMZZ3wgIIIPBETwgYAIPhAQwQcCIvhA\nQAQfCChzHN/MNkj6vqRed7+6smy5pAWSDlZWW+bu6Q94L6issdrt27cn66+//nqynjXOfvvtt+fa\nHrVlHbus+jXXXNPIdgqlnjP+M5JmDLJ8tbt/p/I1LEMPRJUZfHd/U9LhQUqcioBhKs9z/EVmtsPM\nfmZm6XmeABTKUO/VXyfpUXd3M/sXSaslza+1cmdn5+nHpVJJpVJpiLsFUEu5XFa5XK5r3SEF390P\nVX37tKTfpdavDj6A5hh4Ul2xYkXNdeu91DdVPac3s/FVtR9I2nVGHQJoq3qG856TVJI01sz2S1ou\nabqZTZN0UlKXpB82sUcADZYZfHe/Y5DFzzShl0L68ssvk/WvvvoqWb/sssuS9VtuueWMezpbZN1D\nceLEiWR97dq1yXrWOP1tt92WrC9dujRZH864cw8IiOADARF8ICCCDwRE8IGACD4QEMEHAuJz9Zvs\nggsuSNZHjx7dok5aL+84/ZNPPpmsL1myJFmfMmVKsr5s2bJkfeTIkcn6cMYZHwiI4AMBEXwgIIIP\nBETwgYAIPhAQwQcCYhy/ye66665kfbh/bn5qrL6npye57apVq5L1devWJevz5s1L1tevX5+sZxnu\n/zYpnPGBgAg+EBDBBwIi+EBABB8IiOADARF8ICDLes907h2YebP3kUdWb2+99VayfsMNNyTrU6dO\nTdY/+OCDZL3dso7P888/X7N2//33J7c9fHiwSZjr33716tXJ+tk8Dl8PM5O7D3oQOOMDARF8ICCC\nDwRE8IGACD4QEMEHAiL4QECZ78c3s4mSNknqkHRS0tPuvtbMLpX0a0mTJXVJmuPunzax17bIGgvO\nqnd3dyfrjz76aLI+f/78ZD3rc/nffffdZD3rPetvvPFGst7V1VWzdvnllye3nTt3brJ+3333JevR\nx+nzqOeMf0LSj939ryT9jaQfmdlfSnpY0h/c/duSXpW0tHltAmikzOC7+wF331F5fEzSHkkTJc2S\ntLGy2kZJtzarSQCNdUbP8c1siqRpkv4oqcPde6W+Pw6SxjW6OQDNUfdn7pnZaEm/lbTY3Y+Z2cCb\nuGve1N3Z2Xn6calUUqlUOrMuAWQql8sql8t1rVtX8M3sXPWF/hfuvqWyuNfMOty918zGSzpYa/vq\n4ANojoEn1RUrVtRct95L/Z9L2u3ua6qWvSjp3srjeyRtGbgRgGKqZzjvOkl3StppZtvVd0m/TNJP\nJf3GzP5J0j5Jc5rZKIDG4f34Gb1t3bo1Wc96P35eEyZMSNbHjBmTrO/cubOR7XzNjBkzatZmzpyZ\n3HbRokW59s04fhrvxwfQD8EHAiL4QEAEHwiI4AMBEXwgIIIPBMQ4fkZvn332WbI+Z076vqVXXnkl\n1/6z5B3LHjcu/d6qhQsXJuuPPPLIkPfNOHxzMY4PoB+CDwRE8IGACD4QEMEHAiL4QEAEHwgo/Dh+\nlqzejx49mqxv2rQpWV+8ePEZ91Qtayx85cqVyfqCBQuS9bFjx+baP9qHcXwA/RB8ICCCDwRE8IGA\nCD4QEMEHAiL4QECM4+d0Nv9uEuP0wxnj+AD6IfhAQAQfCIjgAwERfCAggg8ElBl8M5toZq+a2btm\nttPM7qssX25mH5nZO5Wv9JzIAAojcxzfzMZLGu/uO8xstKT/lDRL0j9IOuruqzO2P6vH8YGiSo3j\nn5u1sbsfkHSg8viYme2RNOHUz25YlwBa5oye45vZFEnTJP1HZdEiM9thZj8zs4sb3BuAJqk7+JXL\n/N9KWuzuxyStk/Qtd5+mviuC5CU/gOLIvNSXJDM7V32h/4W7b5Ekdz9UtcrTkn5Xa/vOzs7Tj0ul\nkkql0hBaBZBSLpdVLpfrWreuN+mY2SZJn7j7j6uWja88/5eZ/bOk77r7HYNsy4t7QBukXtyr51X9\n6yS9LmmnJK98LZN0h/qe75+U1CXph+7eO8j2BB9og1zBb8DOCT7QBrwtF0A/BB8IiOADARF8ICCC\nDwRE8IGACD4QEMEHAiL4QEAEHwiI4AMBEXwgoJYHv973C7cL/eVT5P6K3JvU2v4I/gD0l0+R+yty\nb9JZHnwA7UfwgYBa8kEcTd0BgJra9gk8AIqHS30gIIIPBNSy4JvZTDN7z8z2mtmSVu23XmbWZWb/\nZWbbzeztAvSzwcx6zey/q5ZdamYvm9n7Zvbv7Zy9qEZ/hZlIdZDJXu+vLC/EMWz3ZLQteY5vZiMk\n7ZV0k6Q/S9omaa67v9f0ndfJzD6U9NfufrjdvUiSmf2tpGOSNrn71ZVlP5X0P+6+qvLH81J3f7hA\n/S1XHROptkJistd5KsAxzDsZbV6tOuNfK+lP7r7P3Y9L+pX6fskiMRXoqY+7vylp4B+hWZI2Vh5v\nlHRrS5uqUqM/qSATqbr7AXffUXl8TNIeSRNVkGNYo7+WTUbbqv/RJ0jqrvr+I/3/L1kULun3ZrbN\nzBa0u5kaxp2atKQyi9G4NvczmMJNpFo12esfJXUU7Ri2YzLawpzhCuA6d/+OpFsk/ahyKVt0RRuL\nLdxEqoNM9jrwmLX1GLZrMtpWBb9H0jervp9YWVYY7v5x5b+HJG1W39OTouk1sw7p9HPEg23upx93\nP1Q1bdLTkr7bzn4Gm+xVBTqGtSajbcUxbFXwt0m6wswmm9lISXMlvdiifWcys1GVv7wys29I+p6k\nXe3tSlLfc73q53svSrq38vgeSVsGbtBi/fqrBOmUH6j9x/Dnkna7+5qqZUU6hl/rr1XHsGV37lWG\nJdao74/NBnf/SUt2XAczm6q+s7yrb+rwX7a7PzN7TlJJ0lhJvZKWS/o3Sf8qaZKkfZLmuPuRAvU3\nXXVMpNqi/mpN9vq2pN+ozccw72S0uffPLbtAPLy4BwRE8IGACD4QEMEHAiL4QEAEHwiI4AMBEXwg\noP8DyWBnmMFJ3d4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103dab978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_values = training_data_list[1].split(',')\n",
    "image_array = numpy.asfarray(all_values[1:]).reshape((28,28))\n",
    "matplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaled_input = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(scaled_input)\n",
    "# print(all_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "onodes = 10\n",
    "targets = np.zeros(onodes) + 0.01\n",
    "targets[(int(all_values[0]))] = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
